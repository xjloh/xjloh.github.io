<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>CS 474/574 Machine Learning HW 1</title>
  <style type="text/css">
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="slideous/slideous.css" />
  
  <script src="slideous/slideous.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div id="statusbar">
<span style="float:right;">
<span style="margin-right:4em;font-weight:bold;"><span id="slideidx"></span> of {$slidecount}</span>
<button id="homebutton" title="first slide">1</button>
<button id="prevslidebutton" title="previous slide">&laquo;</button>
<button id="previtembutton" title="previous item">&lsaquo;</button>
<button id="nextitembutton" title="next item">&rsaquo;</button>
<button id="nextslidebutton" title="next slide">&raquo;</button>
<button id="endbutton" title="last slide">{$slidecount}</button>
<button id="incfontbutton" title="content">A+</button>
<button id="decfontbutton" title="first slide">A-</button>
<select id="tocbox" size="1"><option></option></select>
</span>
<span id="eos">&frac12;</span>
<span title="{$location}, {$date}">{$title}, {$author}</span>
</div>
<div class="slide titlepage">
  <h1 class="title"><p>CS 474/574 Machine Learning<br />
HW 1</p></h1>
  <p class="author">
<p>Xin Jun Loh<br />
Dept. of Computer Science<br />
Iowa State University<br />
Ames, IA, USA<br />
</p>
  </p>
</div>
<div id="warm-up" class="slide section level1">
<h1>Warm up</h1>
<ul>
<li><p>Newton first law of motion: If a body is at rest or moving at a constant speed in a straight line, it will remain at rest or keep moving in a straight line at constant speed unless it is acted upon by a force.</p></li>
<li><p>Einstein’s mass-energy equation: <span class="math inline"><em>E</em> = <em>m</em><em>c</em><sup>2</sup></span></p></li>
<li><p>time complexity of Quicksort on average in Big-O notation: <span class="math inline"><em>O</em>(<em>n</em><em>l</em><em>o</em><em>g</em><em>n</em>)</span></p></li>
</ul>
</div>
<div id="section" class="slide section level1">
<h1></h1>
<p>What are the three types of machine learning?</p>
<p>The three types of machine learning are supervised learning, unsupervised learning and reinforcement learning.</p>
</div>
<div id="section-1" class="slide section level1">
<h1></h1>
<p>The minimal dimension of the vector is 10 because there are 5 categories and one-hot encoding is used on the types of kiosk.</p>
</div>
<div id="representation-of-x" class="slide section level1">
<h1>Representation of <span class="math inline"><em>x</em></span></h1>
<ul>
<li><span class="math inline"><em>x</em></span> is usually not a simple (vector of) number(s). How to tell it to a computer?</li>
<li>Example: bananas vs. apples</li>
<li><strong>Feature engineering</strong>: manually craft functions to <strong>extract</strong> features from raw data, e.g,. SIFT, bag-of-words.</li>
<li>Automated feature extraction in deep learing: E.g., filters in CNNs.</li>
<li>If <span class="math inline"><em>x</em></span> involves categorical values (e.g., gender), there are usually two approaches: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"><strong>One-hot encoding</strong></a> and <a href=""><strong>embedding</strong></a> (in DL context, to be discussed later).</li>
</ul>
</div>
<div id="supervised-ml" class="slide section level1">
<h1>Supervised ML</h1>
<ul>
<li>Given many pairs of inputs and outputs: <span class="math inline">{(<strong>X</strong><sub><strong>1</strong></sub><strong>,</strong> <strong>y</strong><sub><strong>1</strong></sub>), (<strong>X</strong><sub><strong>2</strong></sub><strong>,</strong> <strong>y</strong><sub><strong>2</strong></sub>), …, (<strong>X</strong><sub><strong>N</strong></sub><strong>,</strong> <strong>y</strong><sub><strong>N</strong></sub>)}</span>,</li>
<li>that underline a “black-box” function <span class="math inline"><em>f</em> : ℝ<sup><em>n</em></sup> ↦ ℝ<sup><em>m</em></sup></span> such that <span class="math inline">∀<em>i</em> ∈ [1..<em>n</em>], <em>f</em>(<strong>X</strong><sub><em>i</em></sub>) = <strong>y</strong><sub><em>i</em></sub></span>,</li>
<li>construct a function <span class="math inline"><em>f̂</em></span> that approximates the function <span class="math inline"><em>f</em></span>.</li>
<li>“approximate”: usually <span class="math inline">min ||<em>f̂</em>(<em>x</em>) − <em>f</em>(<em>x</em>)||<sup><em>p</em></sup></span> where <span class="math inline"><em>p</em></span> is usually 1 or 2. <a href="https://en.wikipedia.org/wiki/Norm_(mathematics)">See <span class="math inline">ℓ<sub><em>p</em></sub></span>-norm</a> . <!-- - In other words, $f$ is a black box. And we need to find $\hat{f}$ that mimick the black box.  --></li>
<li>The process of finding the approximation function <span class="math inline"><em>f̂</em></span> is called <strong>training</strong> or <strong>learning</strong>.</li>
<li><span class="math inline"><em>f̂</em></span> is called a <strong>model</strong> or an <strong>estimator</strong>.</li>
<li><span class="math inline"><strong>X</strong><sub><strong>i</strong></sub></span>: an <strong>input</strong> (especially when raw data is used as the input) or <strong>feature vector</strong> (if using feature engineering).</li>
<li><span class="math inline"><strong>y</strong><sub><strong>i</strong></sub></span>, often <span class="math inline"> ∈ ℝ<sup>1</sup></span> a <strong>label</strong> (in classification) or <strong>target</strong> (used more generally and lately).</li>
<li>Classification vs. Regression: When <span class="math inline"><em>y</em></span> is continuous or discrete. In modern DL context, such division is usually no mentioned, expecially in generative tasks.</li>
</ul>
</div>
</body>
</html>
